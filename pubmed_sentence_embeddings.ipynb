{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: pyarrow in ./.venv/lib/python3.11/site-packages (17.0.0)\r\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (4.66.4)\r\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.11/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: sentence-transformers in ./.venv/lib/python3.11/site-packages (3.0.1)\r\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.0.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas) (2024.1)\r\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk) (2024.7.24)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.43.3)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (2.4.0)\r\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.5.1)\r\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.14.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (0.24.3)\r\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (10.4.0)\r\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.15.4)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.6.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\r\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\r\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\r\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.2.2)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.7.4)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.0\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas pyarrow tqdm nltk sentence-transformers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T15:24:22.928794Z",
     "start_time": "2024-07-30T15:24:20.970392Z"
    }
   },
   "id": "208659a64b150ecf"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jtr4v/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from xml.etree import ElementTree as ET\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T15:24:22.937417Z",
     "start_time": "2024-07-30T15:24:22.932953Z"
    }
   },
   "id": "5fb35bc287c7017f"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f8fc439",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T15:24:22.939960Z",
     "start_time": "2024-07-30T15:24:22.936252Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read the PMIDs from the file\n",
    "pmid_file_path = './pmids.txt'\n",
    "with open(pmid_file_path, 'r') as f:\n",
    "    pmids = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8afdb72f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T15:24:22.977574Z",
     "start_time": "2024-07-30T15:24:22.940076Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to fetch a PubMed article in XML format by its PMID\n",
    "def fetch_pubmed_article(pmid):\n",
    "    url = f\"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=pubmed&id={pmid}&retmode=xml\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf6d52ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T15:24:23.721737Z",
     "start_time": "2024-07-30T15:24:22.978705Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5eca4bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-30T15:24:24.241402Z",
     "start_time": "2024-07-30T15:24:23.723409Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading PubMed Articles: 100%|██████████| 2/2 [00:00<00:00,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to ./data/sentence_embeddings.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch articles and process them\n",
    "pmid_list = []\n",
    "sentence_list = []\n",
    "embedding_list = []\n",
    "\n",
    "for pmid in tqdm(pmids[0:2], desc=\"Downloading PubMed Articles\"):\n",
    "    article_xml = fetch_pubmed_article(pmid)\n",
    "    if article_xml:\n",
    "        # Parse the XML to extract the abstract\n",
    "        root = ET.fromstring(article_xml)\n",
    "        abstract_texts = root.findall(\".//AbstractText\")\n",
    "        abstract = \" \".join(abstract_text.text for abstract_text in abstract_texts if abstract_text is not None)\n",
    "        \n",
    "        # Tokenize the abstract into sentences\n",
    "        sentences = sent_tokenize(abstract)\n",
    "        \n",
    "        # Generate embeddings for each sentence\n",
    "        embeddings = model.encode(sentences)\n",
    "        \n",
    "        # Store the PMIDs, sentences, and embeddings\n",
    "        pmid_list.extend([pmid] * len(sentences))\n",
    "        sentence_list.extend(sentences)\n",
    "        embedding_list.extend(embeddings)\n",
    "\n",
    "# Create a DataFrame with PMIDs, sentences, and embeddings\n",
    "data = {'PMID': pmid_list, 'sentence': sentence_list, 'embedding': embedding_list}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to Parquet format\n",
    "parquet_file_path = './data/sentence_embeddings.parquet'\n",
    "df.to_parquet(parquet_file_path, engine='pyarrow', index=False)\n",
    "\n",
    "print(f\"Embeddings saved to {parquet_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-30T15:24:24.241790Z",
     "start_time": "2024-07-30T15:24:24.239626Z"
    }
   },
   "id": "6d7b25f5dc6704b8"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
